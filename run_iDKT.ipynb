{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from data import load_data\n",
    "# from deep_knowledge_tracing_model import DeepKnowledgeTracing\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from ESF_iDKT import RNN\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=2\n",
    "parser = argparse.ArgumentParser(description='DKT_LSTM model')\n",
    "parser.add_argument('-epsilon', type=float, default=0.1, help='Epsilon value for Adam Optimizer')\n",
    "parser.add_argument('-l2_lambda', type=float, default=0.3, help='Lambda for l2 loss')\n",
    "parser.add_argument('-learning_rate', type=float, default=0.001, help='Learning rate')\n",
    "parser.add_argument('-max_grad_norm', type=float, default=20, help='Clip gradients to this norm')\n",
    "parser.add_argument('-keep_prob', type=float, default=0.6, help='Keep probability for dropout')\n",
    "parser.add_argument('-hidden_layer_num', type=int, default=1, help='The number of hidden layers')\n",
    "parser.add_argument('-concept_num', type=int, default=5, help='The number of concept')\n",
    "parser.add_argument('-evaluation_interval', type=int, default=5, help='Evalutaion and print result every x epochs')\n",
    "parser.add_argument('-batch_size', type=int, default=8, help='Batch size for training')\n",
    "parser.add_argument('-epochs', type=int, default=100, help='Number of epochs to train')\n",
    "parser.add_argument('-allow_soft_placement', type=bool, default=True, help='Allow device soft device placement')\n",
    "parser.add_argument('-log_device_placement', type=bool, default=False, help='Log placement ofops on devices')\n",
    "# parser.add_argument('-train_data_path', type=str, default='./遗忘_学生500题目60概念数5/答题序列数据_train'+str(index)+'.csv', help='Path to the training dataset')\n",
    "# parser.add_argument('-test_data_path', type=str, default='./遗忘_学生500题目60概念数5/答题序列数据_test'+str(index)+'.csv',help='Path to the testing dataset')\n",
    "# parser.add_argument('-qm_data_path', type=str, default='./遗忘_学生500题目60概念数5/题目知识点数据'+str(index)+'.csv',help='path to read q_matrix')\n",
    "parser.add_argument('-train_data_path', type=str, default='./datasets/atc_datasets/s500_q10_kc5/s500_q10_kc5_train0.csv', help='Path to the training dataset')\n",
    "parser.add_argument('-test_data_path', type=str, default='./datasets/atc_datasets/s500_q10_kc5/s500_q10_kc5_test0.csv',help='Path to the testing dataset')\n",
    "# parser.add_argument('-qm_data_path', type=str, default='./qm_data/jtr/Meiosis_qm4.npy',help='path to read q_matrix')\n",
    "parser.add_argument('-qm_data_path', type=str, default='./datasets/atc_datasets/s500_q10_kc5/qm_atc2.npy',help='path to read q_matrix')\n",
    "parser.add_argument('-origin_DKT', type=str, default=True,help='Path to the testing dataset')\n",
    "parser.add_argument('-hidden_size', type=int, default=10, help='The number of hidden nodes')\n",
    "\n",
    "args = parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(auc_file, m, optimizer, students, batch_size, num_steps, num_skills, q_matrix, state_writer, training=True, epoch=1):\n",
    "    \"\"\"Runs the model on the given data.\"\"\"\n",
    "    #读取参数\n",
    "    lr = args.learning_rate # learning rate\n",
    "    train_path = args.train_data_path\n",
    "    concept_num = args.concept_num\n",
    "    hidden_size = args.hidden_size\n",
    "    #用于统计标签计算AUC和loss\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    total_loss = 0\n",
    "    total_auc = 0\n",
    "    #分批次处理数据\n",
    "    index = 0\n",
    "    batch_num = 0\n",
    "    while(index+batch_size < len(students)):\n",
    "        batch_num+=1\n",
    "        #x为输入的答题数据，target_id为要预测的答题题目编号数据，不足的补齐-1\n",
    "        x = np.zeros((batch_size,num_steps))\n",
    "        p = np.zeros((batch_size, num_steps))\n",
    "        target_id = np.ones((batch_size, num_steps))\n",
    "        target_id = -target_id\n",
    "        #result为输入的答题结果数据，target_correctness为预测的答题结果\n",
    "        result = np.zeros((batch_size,num_steps))\n",
    "        target_correctness = []\n",
    "        \n",
    "        answer_print=[]\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            #student的格式：(['4'], ['77', '77', '32', '32'], ['1', '0', '0', '0'])\n",
    "            student = students[index+i]\n",
    "            #problem_ids:该学生答题序列的题目编号列表\n",
    "            problem_ids = student[1]\n",
    "            #correctness:该学生答题序列的结果列表\n",
    "            correctness = student[2]\n",
    "            tmp_print = []\n",
    "            for l in range(len(problem_ids)):\n",
    "                tmp_print.append('('+str(problem_ids[l])+','+str(correctness[l])+')')\n",
    "            answer_print.append(tmp_print)\n",
    "            #答题序列的最后一个作为预测，前面的作为输入\n",
    "            for j in range(len(problem_ids)-1):\n",
    "                #生成输入数据\n",
    "                x[i,j] = int(problem_ids[j])\n",
    "                result[i,j] = int(correctness[j])\n",
    "                p[i,j] = int(problem_ids[j+1])\n",
    "                target_id[i,j] = int(problem_ids[j+1])\n",
    "                target_correctness.append(int(correctness[j+1]))\n",
    "                actual_labels.append(int(correctness[j+1]))\n",
    "        index += batch_size\n",
    "        \n",
    "        #将得到的输入训练答题数据转化为tensor，并展开得到onehot格式\n",
    "        x = torch.tensor(x, dtype = torch.int64)\n",
    "        x = torch.unsqueeze(x, 2)\n",
    "        q_hot = torch.FloatTensor(batch_size, num_steps, num_skills)\n",
    "        q_hot.zero_()\n",
    "        q_hot.scatter_(2,x,1)\n",
    "        #将得到的输入预测题号转化为tensor，并展开得到onehot格式\n",
    "        target_id = torch.tensor(target_id, dtype = torch.int64)\n",
    "        target_id = torch.unsqueeze(target_id, 2)\n",
    "        p = torch.tensor(p, dtype = torch.int64)\n",
    "        p = torch.unsqueeze(p, 2)\n",
    "        next_q_hot = torch.FloatTensor(batch_size, num_steps, num_skills)\n",
    "        next_q_hot.zero_()\n",
    "        next_q_hot.scatter_(2,p,1)\n",
    "        #将训练的答题结果数据转化为tensor\n",
    "        result = torch.tensor(result, dtype = torch.int64)\n",
    "        target_correctness = torch.tensor(target_correctness, dtype=torch.float)\n",
    "\n",
    "        #生成mask矩阵，用于将区分有效数据和无效数据，计算loss时只考虑有效数据\n",
    "        mask=[]\n",
    "        label = target_id\n",
    "        label = label.view(-1)\n",
    "        for k in range(label.shape[0]):\n",
    "            if label[k] == -1:\n",
    "                mask.append(0)\n",
    "            else:\n",
    "                mask.append(1)\n",
    "        mask = torch.tensor(mask).cuda()\n",
    "        mask = mask.byte()\n",
    "#         print(\"q_hot.shape:\",q_hot.shape)\n",
    "#         print(\"result.shape:\",result.shape)\n",
    "#         print(\"next_q_hot.shape:\",next_q_hot.shape)\n",
    "        #开始训练\n",
    "        q_hot.cuda()\n",
    "        result.cuda()\n",
    "        next_q_hot.cuda()\n",
    "        target_correctness.cuda()\n",
    "        if training:\n",
    "            optimizer.zero_grad()\n",
    "            out = m(q_hot, result, next_q_hot, concept_num)\n",
    "            #out的格式：(output_pred，h_t)\n",
    "            output_pred = out[0]\n",
    "            #利用mask矩阵从预测结果中取出有效数据\n",
    "            output_pred = output_pred.view(-1)\n",
    "            output_pred = torch.masked_select(output_pred, mask)\n",
    "            \n",
    "            #根据预测结果计算loss \n",
    "            logits = output_pred.cpu()\n",
    "            preds = torch.sigmoid(logits)\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            loss = criterion(logits, target_correctness)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            for p in preds:\n",
    "                pred_labels.append(p.item())\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = m(q_hot, result, next_q_hot, concept_num)\n",
    "                output_pred = out[0]\n",
    "                #利用mask矩阵从预测结果中取出有效数据\n",
    "                output_pred = output_pred.view(-1)\n",
    "                output_pred = torch.masked_select(output_pred, mask)\n",
    "                logits = output_pred.cpu()\n",
    "                preds = torch.sigmoid(logits)\n",
    "                criterion = nn.BCEWithLogitsLoss()\n",
    "                loss = criterion(logits, target_correctness)\n",
    "                for p in preds:\n",
    "                    pred_labels.append(p.item())\n",
    "                total_loss += loss.item()\n",
    "#                 刻画学生能力变化曲线\n",
    "                stu_state = out[1]\n",
    "#                 for n in range(0,3):\n",
    "# #                     print(len(batch_meta))\n",
    "# #                     print(len(batch_meta[n]))\n",
    "#                     state_writer.add_embedding(\n",
    "#                         mat = stu_state[n],\n",
    "#                         metadata = batch_meta[n],\n",
    "#                         global_step = batch_num*batch_size+n,\n",
    "#                         tag = str(epoch)\n",
    "#                     )\n",
    "                \n",
    "                for s in range(stu_state.shape[0]):\n",
    "#                     print(str(batch_num*batch_size+s))\n",
    "                    ans_len = len(answer_print[s])\n",
    "#                     print(answer_print[s])\n",
    "                    state_writer.add_embedding(\n",
    "                    mat=torch.sigmoid(stu_state[s][:ans_len,:]),#学生的能力状态向量（学生数量*hidden_size）每行表示一个数据\n",
    "#                     metadata=time_list,#时间编号，对应时间步num_steps\n",
    "#                     metadata=input_data[i].numpy().tolist(),\n",
    "                    metadata = answer_print[s],\n",
    "                    global_step=(batch_num-1)*batch_size+s,#第几个学生\n",
    "                    tag=str(epoch) #第几个轮次\n",
    "                )\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(actual_labels, pred_labels, pos_label=1)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        total_auc += auc\n",
    "        r2 = r2_score(actual_labels, pred_labels)\n",
    "    average_auc = total_auc/batch_num\n",
    "    average_loss = total_loss/batch_num\n",
    "    print(\"Epoch: {},   average_AUC: {}, average_loss:{}\".format(epoch,  average_auc,average_loss))\n",
    "    with open(auc_file, 'a') as file:\n",
    "        string_auc = \"Epoch:\"+str(epoch)+\"  average_AUC:\"+str(average_auc)+\"  average_loss:\"+str(average_loss)+\"\\n\"\n",
    "        file.write(string_auc)\n",
    "    return average_auc,average_loss,actual_labels,pred_labels          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_data_path = args.train_data_path\n",
    "    test_data_path  = args.test_data_path\n",
    "    batch_size = args.batch_size\n",
    "    concept_num = args.concept_num\n",
    "    qm_data_path = args.qm_data_path\n",
    "    hidden_size = args.hidden_size\n",
    "    \n",
    "    \n",
    "    torch.cuda.set_device(1)\n",
    "    #读取数据\n",
    "    train_students, train_max_num_problems, train_max_skill_num = load_data(train_data_path)\n",
    "#     num_steps = train_max_num_problems\n",
    "#     num_skills = train_max_skill_num\n",
    "    num_layers = 3\n",
    "    test_students, test_max_num_problems, test_max_skill_num = load_data(test_data_path)\n",
    "    num_steps = max(train_max_num_problems, test_max_num_problems)\n",
    "    num_skills = max(train_max_skill_num, test_max_skill_num)\n",
    "    #读取q-matrix\n",
    "#     q_matrix = np.loadtxt(qm_data_path,delimiter=',')\n",
    "    q_matrix = np.load(qm_data_path)\n",
    "    q_matrix = torch.from_numpy(q_matrix)\n",
    "    q_matrix = torch.tensor(q_matrix, dtype = torch.float)\n",
    "    q_matrix.cuda()\n",
    "    print(\"q_matrix.shape:\",q_matrix.shape)\n",
    "#     print(q_matrix)\n",
    "    \n",
    "    print(\"hhm print---最大时间步长num_steps=\",num_steps)\n",
    "    print(\"hhm print---题目数量num_skills=\",num_skills)\n",
    "    args.origin_DKT = False\n",
    "    model = RNN(num_skills,concept_num,num_skills,hidden_size,num_layers)\n",
    "\n",
    "    #初始化kc层权重为q-matrix\n",
    "    model.kc.weight = torch.nn.Parameter(q_matrix.t().cuda())\n",
    "    model = torch.nn.DataParallel(model,device_ids=[1])\n",
    "    model.cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, eps=args.epsilon)\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=args.learning_rate)\n",
    "    now=datetime.datetime.now().replace(microsecond=0) \n",
    "    time_now = (now + datetime.timedelta(hours=8))\n",
    "#     state_writer = SummaryWriter('stu_state/'+'DKT_a_kc30_'+str(num_layers)+'层')\n",
    "    state_writer = SummaryWriter('stu_state/'+'m7_e5_s500_q10_kc'+str(concept_num)+'_h'+str(num_layers)+'层')\n",
    "    auc_file = \"result/m7_e5_s500_q10_kc-\"+str(concept_num)+\"_h-\"+str(hidden_size)+\".txt\"\n",
    "    test_epoch=0\n",
    "    for i in range(args.epochs):\n",
    "        auc,loss,actual_labels,pred_labels = run_epoch(auc_file,model, optimizer,  train_students, batch_size, num_steps, num_skills, q_matrix, state_writer, epoch=i)    \n",
    "\n",
    "#         kc_weight = model.module.kc.weight.cpu().detach().numpy()\n",
    "#         print(len(kc_weight))\n",
    "        # Testing\n",
    "        if ((i + 1) % args.evaluation_interval == 0):\n",
    "            auc,loss,actual_labels,pred_labels = run_epoch(auc_file,model, optimizer, test_students, batch_size, num_steps, num_skills, q_matrix, state_writer, training=False, epoch=test_epoch)\n",
    "            print('Testing')\n",
    "            kc_weight = model.module.kc.weight.cpu().detach().numpy()\n",
    "#             np.save('./atc1_kc_weight_h10/atc1_kcweight_'+str(test_epoch)+'.npy', kc_weight)\n",
    "            test_epoch+=1\n",
    "            # print(rmse, auc, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of rows is 1200\n",
      "The number of students is  400\n",
      "Finish reading data\n",
      "the number of rows is 300\n",
      "The number of students is  100\n",
      "Finish reading data\n",
      "q_matrix.shape: torch.Size([10, 5])\n",
      "hhm print---最大时间步长num_steps= 27\n",
      "hhm print---题目数量num_skills= 10\n",
      "Epoch: 0,   average_AUC: 0.6147361335208912, average_loss:0.6404476773982145\n",
      "Epoch: 1,   average_AUC: 0.618649653271812, average_loss:0.6170697394682436\n",
      "Epoch: 2,   average_AUC: 0.6528048780010961, average_loss:0.6005861892992136\n",
      "Epoch: 3,   average_AUC: 0.7088022154111351, average_loss:0.5786026539851208\n",
      "Epoch: 4,   average_AUC: 0.7297602576684428, average_loss:0.5588855220347034\n",
      "Epoch: 0,   average_AUC: 0.7052532616370253, average_loss:0.5710770313938459\n",
      "Testing\n",
      "Epoch: 5,   average_AUC: 0.7397163085690943, average_loss:0.5478881190017778\n",
      "Epoch: 6,   average_AUC: 0.7439751857742655, average_loss:0.5430096357452626\n",
      "Epoch: 7,   average_AUC: 0.7460951936314087, average_loss:0.5407640027756594\n",
      "Epoch: 8,   average_AUC: 0.7470873668924038, average_loss:0.5395725801282999\n",
      "Epoch: 9,   average_AUC: 0.7477567421045663, average_loss:0.5388183636324746\n",
      "Epoch: 1,   average_AUC: 0.714657424316059, average_loss:0.5625956927736601\n",
      "Testing\n",
      "Epoch: 10,   average_AUC: 0.7482500647364375, average_loss:0.5382561574176866\n",
      "Epoch: 11,   average_AUC: 0.7485647411982137, average_loss:0.5377927367784539\n",
      "Epoch: 12,   average_AUC: 0.748875434610493, average_loss:0.5373900356341381\n",
      "Epoch: 13,   average_AUC: 0.7493493200440164, average_loss:0.537029721907207\n",
      "Epoch: 14,   average_AUC: 0.7494793735937038, average_loss:0.5367020319919197\n",
      "Epoch: 2,   average_AUC: 0.7157654426683248, average_loss:0.5620743632316589\n",
      "Testing\n",
      "Epoch: 15,   average_AUC: 0.7497462806486506, average_loss:0.5364017200713255\n",
      "Epoch: 16,   average_AUC: 0.7498763345188207, average_loss:0.5361260710930338\n",
      "Epoch: 17,   average_AUC: 0.7501125607575815, average_loss:0.5358731752755691\n",
      "Epoch: 18,   average_AUC: 0.7504118888270881, average_loss:0.535640324256858\n",
      "Epoch: 19,   average_AUC: 0.7505640049820517, average_loss:0.5354238815453588\n",
      "Epoch: 3,   average_AUC: 0.7159523816168414, average_loss:0.5620933150251707\n",
      "Testing\n",
      "Epoch: 20,   average_AUC: 0.7507807765688554, average_loss:0.5352201534777271\n",
      "Epoch: 21,   average_AUC: 0.750881203573931, average_loss:0.5350255662081193\n",
      "Epoch: 22,   average_AUC: 0.7511045405309398, average_loss:0.5348366188759707\n",
      "Epoch: 23,   average_AUC: 0.7513774074799062, average_loss:0.5346510823892088\n",
      "Epoch: 24,   average_AUC: 0.7516196724815961, average_loss:0.5344713263365687\n",
      "Epoch: 4,   average_AUC: 0.7157485010378709, average_loss:0.562267430126667\n",
      "Testing\n",
      "Epoch: 25,   average_AUC: 0.7518962610307858, average_loss:0.5343002610060633\n",
      "Epoch: 26,   average_AUC: 0.7520761126479613, average_loss:0.5341357302908994\n",
      "Epoch: 27,   average_AUC: 0.7522984048896101, average_loss:0.5339771503088425\n",
      "Epoch: 28,   average_AUC: 0.7524669410608074, average_loss:0.5338249346431421\n",
      "Epoch: 29,   average_AUC: 0.7525951819886244, average_loss:0.5336782269331873\n",
      "Epoch: 5,   average_AUC: 0.7155667412312009, average_loss:0.5626219511032104\n",
      "Testing\n",
      "Epoch: 30,   average_AUC: 0.7527234473828871, average_loss:0.5335357712239636\n",
      "Epoch: 31,   average_AUC: 0.7528888025990069, average_loss:0.5333964277286919\n",
      "Epoch: 32,   average_AUC: 0.7529314308878599, average_loss:0.533259316366546\n",
      "Epoch: 33,   average_AUC: 0.7529755101544965, average_loss:0.5331237954752786\n",
      "Epoch: 34,   average_AUC: 0.7530330458026279, average_loss:0.5329893900423633\n",
      "Epoch: 6,   average_AUC: 0.7153683520994968, average_loss:0.5629220133026441\n",
      "Testing\n",
      "Epoch: 35,   average_AUC: 0.753139513037991, average_loss:0.532855820899107\n",
      "Epoch: 36,   average_AUC: 0.7532534106512343, average_loss:0.5327228100932374\n",
      "Epoch: 37,   average_AUC: 0.753346736841086, average_loss:0.5325902274676731\n",
      "Epoch: 38,   average_AUC: 0.7534130104854426, average_loss:0.53245795867881\n",
      "Epoch: 39,   average_AUC: 0.7535681467552156, average_loss:0.5323259964281198\n",
      "Epoch: 7,   average_AUC: 0.715462882743453, average_loss:0.5631449272235235\n",
      "Testing\n",
      "Epoch: 40,   average_AUC: 0.7536790583499205, average_loss:0.5321943188200191\n",
      "Epoch: 41,   average_AUC: 0.7538583152808987, average_loss:0.5320629203806118\n",
      "Epoch: 42,   average_AUC: 0.754005803500119, average_loss:0.5319317737404181\n",
      "Epoch: 43,   average_AUC: 0.7541020158903307, average_loss:0.5318009056607071\n",
      "Epoch: 44,   average_AUC: 0.7542471089166287, average_loss:0.5316702194359838\n",
      "Epoch: 8,   average_AUC: 0.7156641831359423, average_loss:0.5633014912406603\n",
      "Testing\n",
      "Epoch: 45,   average_AUC: 0.7543906237537817, average_loss:0.5315396986445602\n",
      "Epoch: 46,   average_AUC: 0.754541356916071, average_loss:0.5314091778531367\n",
      "Epoch: 47,   average_AUC: 0.7545502920415164, average_loss:0.5312785560987434\n",
      "Epoch: 48,   average_AUC: 0.7546181862349837, average_loss:0.5311476326718623\n",
      "Epoch: 49,   average_AUC: 0.7547290380500286, average_loss:0.5310161496911731\n",
      "Epoch: 9,   average_AUC: 0.7159532311316564, average_loss:0.5634461119771004\n",
      "Testing\n",
      "Epoch: 50,   average_AUC: 0.7547914479354063, average_loss:0.5308838133909264\n",
      "Epoch: 51,   average_AUC: 0.7549348967929129, average_loss:0.5307503111508428\n",
      "Epoch: 52,   average_AUC: 0.7551488613758025, average_loss:0.5306151813390304\n",
      "Epoch: 53,   average_AUC: 0.7553260338642478, average_loss:0.5304780365252981\n",
      "Epoch: 54,   average_AUC: 0.7554103261565848, average_loss:0.5303384613017647\n",
      "Epoch: 10,   average_AUC: 0.7165829515696318, average_loss:0.5635830064614614\n",
      "Testing\n",
      "Epoch: 55,   average_AUC: 0.7556325298532882, average_loss:0.5301959575438986\n",
      "Epoch: 56,   average_AUC: 0.7558274193834914, average_loss:0.5300499097425111\n",
      "Epoch: 57,   average_AUC: 0.7559493087476759, average_loss:0.5298992985365342\n",
      "Epoch: 58,   average_AUC: 0.7561165470484097, average_loss:0.5297424245853813\n",
      "Epoch: 59,   average_AUC: 0.756322837490255, average_loss:0.5295775684775138\n",
      "Epoch: 11,   average_AUC: 0.7168078529669074, average_loss:0.5636953810850779\n",
      "Testing\n",
      "Epoch: 60,   average_AUC: 0.7565207970775633, average_loss:0.5294051103445948\n",
      "Epoch: 61,   average_AUC: 0.7566967591592725, average_loss:0.5292270432929603\n",
      "Epoch: 62,   average_AUC: 0.7570100979000781, average_loss:0.5290429002168228\n",
      "Epoch: 63,   average_AUC: 0.757218559875513, average_loss:0.5288518125913582\n",
      "Epoch: 64,   average_AUC: 0.7575591960254493, average_loss:0.5286530323174535\n",
      "Epoch: 12,   average_AUC: 0.716561824707119, average_loss:0.5640195285280546\n",
      "Testing\n",
      "Epoch: 65,   average_AUC: 0.7577911469879066, average_loss:0.528445981594981\n",
      "Epoch: 66,   average_AUC: 0.7580810072097545, average_loss:0.5282309973726467\n",
      "Epoch: 67,   average_AUC: 0.7582383781846839, average_loss:0.5280096391025855\n",
      "Epoch: 68,   average_AUC: 0.7586162665398348, average_loss:0.5277842927952202\n",
      "Epoch: 69,   average_AUC: 0.7588630520622361, average_loss:0.5275573195243368\n",
      "Epoch: 13,   average_AUC: 0.7148990914350309, average_loss:0.5646471157670021\n",
      "Testing\n",
      "Epoch: 70,   average_AUC: 0.7591495143350586, average_loss:0.5273306686051038\n",
      "Epoch: 71,   average_AUC: 0.7594697075138672, average_loss:0.5271055315222059\n",
      "Epoch: 72,   average_AUC: 0.7597845490606912, average_loss:0.5268824258629157\n",
      "Epoch: 73,   average_AUC: 0.7600930706247516, average_loss:0.5266613485861797\n",
      "Epoch: 74,   average_AUC: 0.7602911077545823, average_loss:0.5264420405942567\n",
      "Epoch: 14,   average_AUC: 0.7139100460434836, average_loss:0.5652915587027868\n",
      "Testing\n",
      "Epoch: 75,   average_AUC: 0.7605771716191934, average_loss:0.5262240895203182\n",
      "Epoch: 76,   average_AUC: 0.7608496152446822, average_loss:0.526007140777549\n",
      "Epoch: 77,   average_AUC: 0.7611695889536775, average_loss:0.5257908403873444\n",
      "Epoch: 78,   average_AUC: 0.7614041275376245, average_loss:0.5255749554050212\n",
      "Epoch: 79,   average_AUC: 0.7616255294466332, average_loss:0.5253590953593351\n",
      "Epoch: 15,   average_AUC: 0.7130245060533059, average_loss:0.5658886979023615\n",
      "Testing\n",
      "Epoch: 80,   average_AUC: 0.7619010223264677, average_loss:0.5251428643051459\n",
      "Epoch: 81,   average_AUC: 0.7622593799753554, average_loss:0.5249258243307775\n",
      "Epoch: 82,   average_AUC: 0.7625230610397574, average_loss:0.5247076646405824\n",
      "Epoch: 83,   average_AUC: 0.7627672811995814, average_loss:0.5244883481337099\n",
      "Epoch: 84,   average_AUC: 0.7630625105524508, average_loss:0.5242680134821911\n",
      "Epoch: 16,   average_AUC: 0.7123585833432378, average_loss:0.5664349049329758\n",
      "Testing\n",
      "Epoch: 85,   average_AUC: 0.7633524825620328, average_loss:0.524046464842193\n",
      "Epoch: 86,   average_AUC: 0.7636723436115157, average_loss:0.5238232460557198\n",
      "Epoch: 87,   average_AUC: 0.7639969868027455, average_loss:0.5235977878375929\n",
      "Epoch: 88,   average_AUC: 0.764300506045964, average_loss:0.5233693414804886\n",
      "Epoch: 89,   average_AUC: 0.7646704068822856, average_loss:0.5231368486978569\n",
      "Epoch: 17,   average_AUC: 0.712402781703917, average_loss:0.5668792401750883\n",
      "Testing\n",
      "Epoch: 90,   average_AUC: 0.7650060859544846, average_loss:0.5228991362513328\n",
      "Epoch: 91,   average_AUC: 0.7653107325000235, average_loss:0.5226548338422969\n",
      "Epoch: 92,   average_AUC: 0.7656065879536164, average_loss:0.5224027481614327\n",
      "Epoch: 93,   average_AUC: 0.7659911593301827, average_loss:0.5221429120521156\n",
      "Epoch: 94,   average_AUC: 0.7664536201070618, average_loss:0.521880567073822\n",
      "Epoch: 18,   average_AUC: 0.7117361034185431, average_loss:0.5675963908433914\n",
      "Testing\n",
      "Epoch: 95,   average_AUC: 0.7667125622918125, average_loss:0.5216199804325493\n",
      "Epoch: 96,   average_AUC: 0.7670330888322985, average_loss:0.5213552123429824\n",
      "Epoch: 97,   average_AUC: 0.767362582665496, average_loss:0.5210878897686394\n",
      "Epoch: 98,   average_AUC: 0.7677295560586352, average_loss:0.5208016524509508\n",
      "Epoch: 99,   average_AUC: 0.7681195481275725, average_loss:0.5205323075761601\n",
      "Epoch: 19,   average_AUC: 0.7110786639107068, average_loss:0.5687243392070135\n",
      "Testing\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
